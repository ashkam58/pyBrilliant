import BigOPlayground from '@/components/BigOPlayground'
import Callout from '@/components/Callout'
import CartoonCard from '@/components/dsa/CartoonCard'
import OperationCounter from '@/components/dsa/OperationCounter'
import BinarySearchViz from '@/components/dsa/BinarySearchViz'
import ReindexingSimulator from '@/components/dsa/ReindexingSimulator'
import DropTheNoise from '@/components/dsa/DropTheNoise'
import TwoInputComplexity from '@/components/dsa/TwoInputComplexity'
import SortingOverview from '@/components/dsa/SortingOverview'
import StopwatchSim from '@/components/dsa/StopwatchSim'
import BigOBarPlot from '@/components/dsa/BigOBarPlot'
import SearchSimulator from '@/components/dsa/SearchSimulator'
import QuizMCQ from '@/components/ui/QuizMCQ'

---
title: Big O (Growth of Functions)
---

# Big O â€” Growth of Functions

Welcome! This lesson introduces Big O notation and gives you an interactive playground to explore how different complexity classes grow as the input size n increases.

<Callout>
This page includes an interactive playground. Use the slider to change n and toggle different complexity classes to see how they compare.
</Callout>

## Visual Playground

<BigOPlayground />

## Quick Theory

Big O notation describes the asymptotic upper bound of how a function grows relative to its input size. Common complexity classes:

- O(1): Constant time â€” does not grow with n.
- O(log n): Logarithmic â€” grows very slowly.
- O(n): Linear â€” grows proportionally to n.
- O(n log n): Linearithmic â€” common in efficient sorting algorithms.
- O(n^2): Quadratic â€” nested loops over n.
- O(2^n): Exponential â€” doubles with each additional input element.

## Examples (spot the Big O)

1. Loop from 0 to n-1 and do O(1) work each iteration.

2. Two nested loops from 0 to n-1 doing O(1) work â€” O(n^2).

3. Binary search on a sorted array â€” O(log n).

## Exercises

### Easy

What is the Big O of the following code?

```js
function sum(arr) {
  let total = 0
  for (let i = 0; i < arr.length; i++) {
    total += arr[i]
  }
  return total
}
```

<details>
<summary>Answer</summary>

O(n)

</details>

### Medium

What is the Big O here?

```js
function pairs(arr) {
  const out = []
  for (let i = 0; i < arr.length; i++) {
    for (let j = i + 1; j < arr.length; j++) {
      out.push([arr[i], arr[j]])
    }
  }
  return out
}
```

<details>
<summary>Answer</summary>

O(n^2)

</details>

### Hard

What is the complexity of generating all subsets of a set of size n (the power set)?

<details>
<summary>Answer</summary>

O(2^n)

</details>

## Try it out

Use the interactive playground above to compare classes across ranges. Tip: switch to logarithmic scale for wide ranges to make exponential growth visible.

---


Happy teaching! If you'd like, I can also add a `big-o-code` interactive page with a CodeRunner that lets students write small functions and measure approximate operation counts.

<StopwatchSim />

## Big-O Complexity Analysis

Big-O notation describes how algorithms scale with input size. It's the most important concept for analyzing algorithm efficiency and is essential for technical interviews.

## Best, Average, Worst â€” Î©, Î˜, O

<CartoonCard emoji="ðŸ§­" title="Three Greek friends" subtitle="Omega (best), Theta (average), Bigâ€‘O (worst)">
When you linearly search a list, the **best** case finds the item first (Î©), the **average** is somewhere in the middle (Î˜), and the **worst** case is last (O). Interviewers usually ask for **Bigâ€‘O** â€” the worst case.
</CartoonCard>

<SearchSimulator />

## Operation Counter & Algorithm Simulation

See how different algorithms count operations as input size grows. Watch the patterns emerge!

<OperationCounter />

## Binary Search Visualization

Binary search is a perfect example of O(log n) complexity. Watch how it divides the search space in half with each step.

<BinarySearchViz />

## List Operations & Reindexing

Understanding why some list operations are expensive is crucial. See how insertions and deletions can require shifting many elements.

<ReindexingSimulator />

## Growth playground

<BigOBarPlot />

## Drop Constants & Lower-Order Terms

Big-O focuses on growth patterns, not exact counts. Learn the art of simplification.

<DropTheNoise />

## Two-Input Complexity: O(a+b) vs O(aÃ—b)

When algorithms take multiple inputs, complexity can be additive or multiplicative. The difference is dramatic!

<TwoInputComplexity />

## Sorting Algorithms Overview

Different sorting algorithms showcase various complexity patterns. Here's your reference guide.

<SortingOverview />

## Assessment Quiz

Test your understanding of Big-O concepts:

<QuizMCQ
question="If one algorithm does 500*n* operations and another does 3*n*, what are their Bigâ€‘O classes?"
choices={["O(500n) vs O(3n)", "Both O(n)", "O(n^2) vs O(n)", "O(log n) vs O(1)"]}
answer="Both O(n)"
explanation="Bigâ€‘O ignores constant multipliers; both are linear."
/>

<QuizMCQ
question="Linear search in the worst case touches how many items?"
choices={["1", "log n", "n", "n^2"]}
answer="n"
explanation="If the target is last or absent, you check the whole list."
/>

<QuizMCQ
question="What's the complexity of inserting at the head of a list with n elements?"
choices={["O(1)", "O(log n)", "O(n)", "O(n^2)"]}
answer="O(n)"
explanation="Inserting at the head requires shifting all existing elements to the right."
/>

<QuizMCQ
question="Binary search on a sorted array of size n has complexity:"
choices={["O(1)", "O(log n)", "O(n)", "O(n log n)"]}
answer="O(log n)"
explanation="Binary search halves the search space with each step, giving logarithmic complexity."
/>

<QuizMCQ
question="For two inputs of size a and b, processing each separately gives complexity:"
choices={["O(a Ã— b)", "O(a + b)", "O(max(a, b))", "O(a^2 + b^2)"]}
answer="O(a + b)"
explanation="Processing inputs separately means a operations + b operations = O(a + b)."
/>

<QuizMCQ
question="Which term dominates in: 5nÂ² + 100n + 1000?"
choices={["5nÂ²", "100n", "1000", "All are equal"]}
answer="5nÂ²"
explanation="For large n, the quadratic term nÂ² grows much faster than linear or constant terms."
/>

<QuizMCQ
question="The space complexity of merge sort is:"
choices={["O(1)", "O(log n)", "O(n)", "O(n^2)"]}
answer="O(n)"
explanation="Merge sort requires additional O(n) space to store the merged subarrays."
/>

<QuizMCQ
question="Which Big-O class grows fastest?"
choices={["O(nÂ²)", "O(2^n)", "O(n log n)", "O(nÂ³)"]}
answer="O(2^n)"
explanation="Exponential growth O(2^n) eventually dominates all polynomial growth rates."
/>

<QuizMCQ
question="Nested loops where outer runs 'a' times and inner runs 'b' times gives:"
choices={["O(a + b)", "O(a Ã— b)", "O(max(a, b))", "O(aÂ² + bÂ²)"]}
answer="O(a Ã— b)"
explanation="Nested loops multiply: for each of the 'a' iterations, we do 'b' work = aÃ—b total."
/>

<QuizMCQ
question="After dropping constants and lower terms, 3n + 7 log n + 5 becomes:"
choices={["O(n)", "O(log n)", "O(3n)", "O(n log n)"]}
answer="O(n)"
explanation="The linear term n dominates the logarithmic term log n for large inputs."
/>

---

**Next stop:** Pointers & mutability â€” where arrows matter more than numbers.
